{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## CS4287 - Neural Network\n",
    "### Assignment 1 - 4th Year Semester 1 2024\n",
    "\n",
    "Adam Collins: 21332967\n",
    "\n",
    "Italo da Silva: 21326312"
   ],
   "id": "5e61c443c72ca5a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Code executes to the end without an error. ",
   "id": "83d747b7aa37043c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score"
   ],
   "id": "e2639accb1bc1569",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. The Data Set \n",
    "#   (a). Visualisation of key attributes.\n",
    "\n",
    "# Loading the csv file and viewing first rows using pandas library\n",
    "housing_data = pd.read_csv('Melbourne_housing_FULL.csv', low_memory=False) \n",
    "\n",
    "# Filtering the Dataset\n",
    "# Dropping every cell that contains a NaN value (there was alot)\n",
    "columns = [\"Suburb\",\"Rooms\",\"Type\",\"Price\",\"Method\",\"SellerG\",\"Date\",\"Distance\",\"Bedroom2\",\"Bathroom\",\"Car\",\"Landsize\",\"BuildingArea\",\"YearBuilt\",\"CouncilArea\",\"Lattitude\",\"Longtitude\",\"Regionname\",\"Propertycount\"]\n",
    "housing_data = housing_data.dropna(subset=columns)\n",
    "\n",
    "# Dropping all the columns that don't contain numbers (there was alot too )\n",
    "housing_data.drop([\"Suburb\", \"Address\", \"Type\", \"Method\", \"SellerG\", \"CouncilArea\", \"Regionname\", \"Date\"], inplace=True, axis=\"columns\")\n",
    "housing_data.head()"
   ],
   "id": "85c8463c5412e41a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Draw graph of correlation between Price and Building Area\n",
    "\n",
    "## Converting the data in the columns to numeric \n",
    "housing_data[['Price', 'BuildingArea']] = housing_data[['Price', 'BuildingArea']].apply(pd.to_numeric)\n",
    "\n",
    "## Reshaping the data to a 2D array in order to plot it in the Linear Regression \n",
    "price = housing_data['Price'].values.reshape(-1,1)\n",
    "building_area = housing_data['BuildingArea'].values.reshape(-1,1)\n",
    "\n",
    "## Creating a Linear Regression model to predict the data for Building Area based on the Price\n",
    "reg = LinearRegression().fit(price, building_area)\n",
    "\n",
    "## Functions to plot the graph\n",
    "plt.plot(housing_data[['Price']], housing_data[['BuildingArea']], '*')\n",
    "plt.plot(housing_data[['Price']], reg.predict(price), 'r')\n",
    "\n",
    "## Adding labels to the graph\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Building Area')\n",
    "plt.title('Price vs Building Area')\n",
    "plt.show()"
   ],
   "id": "97f09daa0f6dc489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# From sample Assignment 1 provided by the lecturer.\n",
    "\n",
    "# Dataframe of key attributes\n",
    "housing_data.corr()\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = housing_data.corr()\n",
    "\n",
    "# Generate Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='jet', cbar=True, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ],
   "id": "3e0e136f35147f78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # 1. The Data Set \n",
    "#   (b). Pre-Processing - Normalisation\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "housing_data[['Rooms', 'Price', 'Distance', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Propertycount']] = scaler.fit_transform(housing_data[['Rooms', 'Price', 'Distance', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Propertycount']])\n",
    "\n",
    "# Dropping Postcode, Landsize and Propertycount as the values are very close to 0\n",
    "# Also dropping Longitude and Langitude columns as they're useless for correlating price as we already have a Distance (to CBD) column.\n",
    "\n",
    "housing_data.drop([\"Postcode\", \"Landsize\", \"Propertycount\", \"Longtitude\", \"Lattitude\"], inplace=True, axis=\"columns\")\n",
    "\n",
    "# Sine we dropped alot of rows previously due to NaN values and Unnecessary data, the rows index stayed the same.\n",
    "# So we now need to reset the index back to normal to avoid confusion and keep them in order.\n",
    "housing_data = housing_data.reset_index(drop=True)\n",
    "\n",
    "housing_data.head()"
   ],
   "id": "fbf5fec53a14808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rows = len(housing_data.axes[0])\n",
    "columns = len(housing_data.axes[1])\n",
    "\n",
    "print(\"Number of columns: \", columns)\n",
    "print(\"Number of rows: \", rows)"
   ],
   "id": "11082663ed5198e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select the features and target variable\n",
    "# Correlating the price of each property based on it's features\n",
    "features = ['Rooms', 'Distance', 'Bedroom2', 'Bathroom', 'Car', 'BuildingArea','YearBuilt']\n",
    "\n",
    "x = housing_data[features]\n",
    "y = housing_data['Price']\n",
    "\n",
    "# Dividing the price column into 5 sections in order to classify correctly and can be used in the output layer of our model.\n",
    "\n",
    "# 0.00 to 0.15 (first section)\n",
    "# 0.15 to 0.38 (second section)\n",
    "# 0.38 to 0.62 (third section)\n",
    "# 0.62 to 0.85 (fourth section)\n",
    "# 0.85 to 1.00 (last section)\n",
    "\n",
    "y = pd.cut(y, bins=[0.00, 0.15, 0.38, 0.62, 0.85, 1.00], labels=[0, 1, 2, 3, 4])\n",
    "print(y)\n",
    "\n",
    "# In order to validate and evaluate the model, we are splitting the dataset into two parts, training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "\n",
    "print(\"\\nx_train shape: \", x_train.shape[0])\n",
    "print(\"x_test shape: \", x_test.shape[0])"
   ],
   "id": "8916f7e1f6a79ff8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T14:25:34.662063Z",
     "start_time": "2024-10-17T14:25:34.542459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(tf.keras.layers.Dense(24, input_shape=(len(features),), activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))  # Output layer for regression - softmax here\n",
    "\n",
    "#softmax classification - why tho ?\n",
    "\n",
    "# Compile the model with mean_squared_error loss function\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(x_test, y_test))"
   ],
   "id": "cf836a9a60844813",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamcollins/PycharmProjects/JJ Assignment 1/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_13\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_32 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m24\u001B[0m)             │           \u001B[38;5;34m192\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m)              │           \u001B[38;5;34m125\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m317\u001B[0m (1.24 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">317</span> (1.24 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m317\u001B[0m (1.24 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">317</span> (1.24 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: category",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[105], line 17\u001B[0m\n\u001B[1;32m     14\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/JJ Assignment 1/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/JJ Assignment 1/.venv/lib/python3.10/site-packages/optree/ops.py:747\u001B[0m, in \u001B[0;36mtree_map\u001B[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001B[0m\n\u001B[1;32m    745\u001B[0m leaves, treespec \u001B[38;5;241m=\u001B[39m _C\u001B[38;5;241m.\u001B[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001B[1;32m    746\u001B[0m flat_args \u001B[38;5;241m=\u001B[39m [leaves] \u001B[38;5;241m+\u001B[39m [treespec\u001B[38;5;241m.\u001B[39mflatten_up_to(r) \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m rests]\n\u001B[0;32m--> 747\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtreespec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mflat_args\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: Invalid dtype: category"
     ]
    }
   ],
   "execution_count": 105
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
