{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## CS4287 - Neural Network\n",
    "### Assignment 1 - 4th Year Semester 1 2024\n",
    "\n",
    "Adam Collins: 21332967\n",
    "\n",
    "Italo da Silva: 21326312"
   ],
   "id": "5e61c443c72ca5a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Code executes to the end without an error. ",
   "id": "83d747b7aa37043c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score"
   ],
   "id": "e2639accb1bc1569",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. The Data Set \n",
    "#   (a). Visualisation of key attributes.\n",
    "\n",
    "# Loading the csv file and viewing first rows using pandas library\n",
    "housing_data = pd.read_csv('Melbourne_housing_FULL.csv', low_memory=False) \n",
    "\n",
    "# Filtering the Dataset\n",
    "# Dropping every cell that contains a NaN value (there was alot)\n",
    "columns = [\"Suburb\",\"Rooms\",\"Type\",\"Price\",\"Method\",\"SellerG\",\"Date\",\"Distance\",\"Bedroom2\",\"Bathroom\",\"Car\",\"Landsize\",\"BuildingArea\",\"YearBuilt\",\"CouncilArea\",\"Lattitude\",\"Longtitude\",\"Regionname\",\"Propertycount\"]\n",
    "housing_data = housing_data.dropna(subset=columns)\n",
    "\n",
    "# Dropping all the columns that don't contain numbers (there was alot too )\n",
    "housing_data.drop([\"Suburb\", \"Address\", \"Type\", \"Method\", \"SellerG\", \"CouncilArea\", \"Regionname\", \"Date\"], inplace=True, axis=\"columns\")\n",
    "housing_data.head()"
   ],
   "id": "85c8463c5412e41a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Draw graph of correlation between Price and Building Area\n",
    "\n",
    "## Converting the data in the columns to numeric \n",
    "housing_data[['Price', 'BuildingArea']] = housing_data[['Price', 'BuildingArea']].apply(pd.to_numeric)\n",
    "\n",
    "## Reshaping the data to a 2D array in order to plot it in the Linear Regression \n",
    "price = housing_data['Price'].values.reshape(-1,1)\n",
    "building_area = housing_data['BuildingArea'].values.reshape(-1,1)\n",
    "\n",
    "## Creating a Linear Regression model to predict the data for Building Area based on the Price\n",
    "reg = LinearRegression().fit(price, building_area)\n",
    "\n",
    "## Functions to plot the graph\n",
    "plt.plot(housing_data[['Price']], housing_data[['BuildingArea']], 'o')\n",
    "plt.plot(housing_data[['Price']], reg.predict(price), 'r')\n",
    "\n",
    "## Adding labels to the graph\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Building Area')\n",
    "plt.title('Price vs Building Area')\n",
    "plt.show()"
   ],
   "id": "97f09daa0f6dc489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# From sample Assignment 1 provided by the lecturer.\n",
    "\n",
    "# Dataframe of key attributes\n",
    "housing_data.corr()\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = housing_data.corr()\n",
    "\n",
    "# Generate Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='jet', cbar=True, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ],
   "id": "3e0e136f35147f78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # 1. The Data Set \n",
    "#   (b). Pre-Processing - Normalisation\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "housing_data[['Rooms', 'Price', 'Distance', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Propertycount']] = scaler.fit_transform(housing_data[['Rooms', 'Price', 'Distance', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Propertycount']])\n",
    "\n",
    "# Only keeping the BuildingArea, Bathroom, Bedroom2 and YearBuilt columns as they are closest correlations to the Price\n",
    "housing_data.drop([\"Rooms\", \"Distance\", \"Postcode\", \"Car\", \"Landsize\", \"Lattitude\", \"Longtitude\", \"Propertycount\"], inplace=True, axis=\"columns\")\n",
    "\n",
    "housing_data.head()"
   ],
   "id": "fbf5fec53a14808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select the features and target variable\n",
    "features = ['BuildingArea', 'Bedroom2', 'Bathroom', 'YearBuilt']\n",
    "target = 'Price'\n",
    "\n",
    "x = housing_data[features]\n",
    "y = housing_data[target]\n",
    "\n",
    "# In order to validate and evaluate the model, we are splitting the dataset into two parts, training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape[0])\n",
    "print(\"x_test shape: \", x_test.shape[0])"
   ],
   "id": "8916f7e1f6a79ff8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(tf.keras.layers.Dense(128, input_shape=(len(features),), activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))  # Output layer for regression\n",
    "\n",
    "# Compile the model with mean_squared_error loss function\n",
    "model.compile(optimizer='adam', loss='MSE', metrics=['mae'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(x_test, y_test))"
   ],
   "id": "cf836a9a60844813",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
